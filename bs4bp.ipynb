{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\ (generic function with 152 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "import Base: \\\n",
    "function LinearAlgebra.Bidiagonal(dv::Vector{T}, ev::Vector{S}, uplo::Symbol) where {T,S}\n",
    "    TS = promote_type(T,S)\n",
    "    return Bidiagonal{TS,Vector{TS}}(dv, ev, uplo)\n",
    "end\n",
    "\n",
    "\n",
    "## The base method narrows the type too much. We'll have to ensure that it's as least as wide as the input\n",
    "function  \\(adjA::Adjoint{<:Any,<:Union{UnitUpperTriangular,UnitLowerTriangular}}, B::AbstractVector)\n",
    "    A = adjA.parent\n",
    "    TAB = promote_type(eltype(A), eltype(B), typeof(zero(eltype(A))*zero(eltype(B)) + zero(eltype(A))*zero(eltype(B))))\n",
    "    BB = similar(B, TAB, size(B))\n",
    "    copyto!(BB, B)\n",
    "    ldiv!(adjoint(convert(AbstractArray{TAB}, A)), BB)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x) = exp(-x)\n",
    "h′(x,y) = -y\n",
    "𝓁(x,y) = sum(abs2,x-y)/2\n",
    "𝓁′(x,y) = x-y\n",
    "init(sizes...) = 0.1randn(sizes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "𝜀 = .0001\n",
    "n = [5,4,3,1]\n",
    "N = length(n)-1\n",
    "B = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params, input; h=h, h′=h′, N=length(params))\n",
    "    δ = [];\n",
    "    X = [input];\n",
    "    for i=1:N\n",
    "        x = sum(params[i] .* [X[i],1])\n",
    "        push!(X,h(x))\n",
    "        push!(δ, h′.(x,X[i+1]))\n",
    "    end\n",
    "    return X,δ\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.042904888226299086, -0.15626856145304235)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params =[[init(),init()] for i=1:N] # W and B\n",
    "x,y = init(),init() # input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [8.47879e-5, 0.00197618]\n",
       " [0.0639805, 0.0654314]  \n",
       " [-0.866442, -0.933566]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "L   = Bidiagonal(zeros(N),[δ[i] * params[i][1] for i=2:N],:L)\n",
    "D   = Diagonal(δ.*[[X[i],1]' for i=1:N])\n",
    "g   = [zeros(N-1);𝓁′(X[N+1],y)]\n",
    "∇J  = D'*((I-L')\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [8.47879e-5, 0.00197618]\n",
       " [0.0639805, 0.0654314]  \n",
       " [-0.866442, -0.933566]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ∇Jfd is gradient calculated with finite differences method\n",
    "∇Jfd = ∇J * 0\n",
    "ϵ    = ∇J * 0\n",
    "for i=1:N, j=1:2       \n",
    "    ϵ[i][j] = 𝜀\n",
    "    ∇Jfd[i][j]=(𝓁(neural_net(params.+ϵ,x)[1][N+1],y)-𝓁(neural_net(params.-ϵ,x)[1][N+1],y))/2𝜀\n",
    "    ϵ[i][j] = .0\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 349 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: +,-,*,/,∘\n",
    "\n",
    "struct LinearMatrixOp # Is parametric type necessary? It causes un-readable error messages and some other issues.\n",
    "    f\n",
    "    fadj\n",
    "end\n",
    "LinearMatrixOp(f::Function) = LinearMatrixOp(f,f)\n",
    "\n",
    "LeftMul(A::Matrix) = LinearMatrixOp(X->A*X, X->A'*X)\n",
    "RightMul(A::Matrix) = LinearMatrixOp(X->X*A, X->X*A')\n",
    "HadMul(A::Matrix) = LinearMatrixOp(X->X.*A)\n",
    "ZeroMul() = LinearMatrixOp(X->Zero())\n",
    "IdentMul() = LinearMatrixOp(X->X) #not neccessary, can be commented\n",
    "\n",
    "Base.zero(::Type{LinearMatrixOp}) = ZeroMul() \n",
    "Base.one(::Type{LinearMatrixOp}) = IdentMul()\n",
    "Base.adjoint(A::LinearMatrixOp) = LinearMatrixOp(A.fadj,A.f)\n",
    "Base.copy(A::LinearMatrixOp) =  LinearMatrixOp(A.f,A.fadj)\n",
    "\n",
    "*(A::LinearMatrixOp,X::Union{AbstractArray,Number}) = A.f(X)\n",
    "-(A::LinearMatrixOp) = LinearMatrixOp(X->-A.f(X), X->-A.fadj(X))\n",
    "∘(A::LinearMatrixOp, B::LinearMatrixOp) = LinearMatrixOp(A.f ∘ B.f, B.fadj ∘ A.fadj)\n",
    "\n",
    "# A zero\n",
    "struct Zero end\n",
    "Base.zero(::Type{Any}) = Zero()\n",
    "+(::Zero, ::Zero) = Zero()\n",
    "-(::Zero, A) = -A\n",
    "+(::Zero, A) = A\n",
    "*(::Zero, ::Zero) = Zero()\n",
    "*(X, ::Zero) = Zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    for i=1:length(params)\n",
    "        x = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(x))\n",
    "        push!(δ,h′.(x,X[i+1]))\n",
    "    end \n",
    "    X,δ\n",
    "end\n",
    "array(x)= fill(x,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: `W_i` and `b_i`s: x_{i+1} <- Wi*x_i .+ b_i\n",
    "params =[[init(n[i+1],n[i]),init(n[i+1])] for i=1:N]\n",
    "x, y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[HadMul(δ[i]) ∘ RightMul(X[i]) HadMul(δ[i])] for i=1:N])\n",
    "ImL = Bidiagonal([I for i in 1:N], -[HadMul(δ[i]) ∘ LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "g = push!(Any[Zero() for i=1:N-1],𝓁′(X[N+1],y))\n",
    "∇J = D'*array.(ImL'\\g);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ∇Jfd is gradient calculated with finite differences method\n",
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(params), wb=1:2\n",
    "    for j=1:length(ϵ[i][wb])\n",
    "        ϵ[i][wb][j] = 𝜀\n",
    "        ∇Jfd[i][wb][j] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "        ϵ[i][wb][j] = .0\n",
    "     end\n",
    "end\n",
    "∇Jfd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       " -0.00407991    0.00285509   -0.0428952    0.000825005  -0.0118724  \n",
       "  0.000410254  -0.000251142   0.00349368  -2.9138e-5     0.000856534\n",
       "  0.000198321  -0.000139445   0.00190502   2.56003e-6    0.000499563\n",
       " -0.00191193    0.00135827   -0.0205804    0.000203086  -0.00526457 "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       " -0.00407991    0.00285509   -0.0428952    0.000825005  -0.0118724  \n",
       "  0.000410254  -0.000251142   0.00349368  -2.9138e-5     0.000856534\n",
       "  0.000198321  -0.000139445   0.00190502   2.56003e-6    0.000499563\n",
       " -0.00191193    0.00135827   -0.0205804    0.000203086  -0.00526457 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Showcase: Densely Connected Matrix Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "function neural_net(params,input;h=h, h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    for i in 1:length(params)\n",
    "       x = broadcast(+,(params[i] .* [X..., I])...)\n",
    "       push!(X,h.(x))\n",
    "       push!(δ,h′.(x,X[i+1]))\n",
    "    end \n",
    "    X,δ\n",
    "end;\n",
    "array(x) = fill(x,1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [[j==i+1 ?  init(n[i+1],1) : init(n[i+1],n[j])  for j=1:i+1] for i=1:N]\n",
    "x,y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Any,2},1}:\n",
       " [[0.0379171 0.0596779 … -0.00351366 -0.0183997; 0.0176358 0.0267665 … -0.000936798 -0.00829942; -0.00426545 -0.00667903 … 0.000503375 0.00207844; -0.0298646 -0.0460088 … 0.00486409 0.0139724]; [0.132619 0.158898 … 0.122803 0.140189; 0.0590691 0.0733649 … 0.0568234 0.0645881; -0.0149404 -0.0176034 … -0.0135742 -0.0151078; -0.106533 -0.120959 … -0.0929069 -0.103307]]                                                \n",
       " [[-0.0270448 -0.0421929 … 0.00362485 0.0128705; 0.00335261 0.00530938 … -0.000566726 -0.00162885; -0.00223139 -0.00341808 … 0.000263075 0.00107243]; [-0.740224 -0.735038 -0.880599 -0.81063; 0.0912298 0.0905783 0.108544 0.0999296; -0.0587999 -0.0583911 -0.0699529 -0.0643888]; [-0.0958499 -0.111914 … -0.086044 -0.0965746; 0.012141 0.0137523 … 0.0105494 0.0116968; -0.00767671 -0.00905481 … -0.00697657 -0.00763726]]\n",
       " [[-0.20336 -0.315236 … 0.0260609 0.0969537]; [-5.50542 -5.46695 -6.54949 -6.02892]; [-6.25354 -5.21931 -5.53321]; [-0.713717 -0.837303 … -0.643339 -0.717522]]                                                                                                                                                                                                                                                                 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[[(HadMul(δ[i]) ∘ RightMul(X[j]))' for j=1:i]' HadMul(δ[i])] for i=1:N])\n",
    "ImL = UnitLowerTriangular(Matrix{Any}(undef,N,N))\n",
    "for i=2:N, j=1:i-1\n",
    "    ImL[i,j] = -HadMul(δ[i]) ∘ LeftMul(params[i][j+1]) \n",
    "end\n",
    "g = push!(Any[Zero() for i=1:N-1],𝓁′(X[N+1],y))\n",
    "∇J = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ∇Jfd is gradient calculated with finite differences method\n",
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(ϵ), j=1:length(ϵ[i]), k=1:length(ϵ[i][j])\n",
    "        ϵ[i][j][k] = 𝜀\n",
    "        ∇Jfd[i][j][k] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "        ϵ[i][j][k] = .0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       "  0.0379171    0.0596779   -0.00049355   -0.00351366   -0.0183997 \n",
       "  0.0176358    0.0267665   -0.000829261  -0.000936798  -0.00829942\n",
       " -0.00426545  -0.00667903  -1.16189e-5    0.000503375   0.00207844\n",
       " -0.0298646   -0.0460088   -0.000608528   0.00486409    0.0139724 "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       "  0.0379171    0.0596779   -0.00049355   -0.00351366   -0.0183997 \n",
       "  0.0176358    0.0267665   -0.000829261  -0.000936798  -0.00829942\n",
       " -0.00426545  -0.00667903  -1.16189e-5    0.000503375   0.00207844\n",
       " -0.0298646   -0.0460088   -0.000608528   0.00486409    0.0139724 "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[1][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
