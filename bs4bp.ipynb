{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x) = exp(-x)\n",
    "h′(x,y) = -y\n",
    "𝓁(x,y) = sum(abs2,x-y)/2\n",
    "𝓁′(x,y) = x-y\n",
    "𝜀 = .0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [0.409429, 1.63166]  \n",
       " [1.5489, -0.610416]  \n",
       " [0.0139285, -1.40057]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3 \n",
    "w = randn(N)\n",
    "b = randn(N)\n",
    "params =[[w[i],b[i]] for i=1:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params, input; h=h, h′=h′, N=length(params))\n",
    "    δ = [];\n",
    "    X = [input];\n",
    "    for i=1:N\n",
    "        x = params[i]⋅[X[i],1]\n",
    "        y = h.(x) \n",
    "        push!(δ, h′.(x,y))\n",
    "        push!(X,y)\n",
    "    end\n",
    "    return X,δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [-0.017232, -0.0742665]\n",
       " [0.0479479, 0.269554]  \n",
       " [-19.3528, -13.8452]   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand()\n",
    "y = 0.5\n",
    "X,δ   = neural_net(params,x)\n",
    "L     = Bidiagonal(zeros(N),δ[2:N].*w[2:N],:L)\n",
    "D     = Diagonal(δ.*[[X[i],1]' for i=1:N])\n",
    "f     = [zeros(N-1);𝓁′(X[N+1],y)]\n",
    "∇J    = D'*((I-L')\\f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [-0.017232, -0.0742665]\n",
       " [0.0479479, 0.269554]  \n",
       " [-19.3528, -13.8452]   "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd = ∇J * 0\n",
    "ϵ    = ∇J * 0\n",
    "for i=1:N, j=1:2       \n",
    "    ϵ[i][j] = 𝜀\n",
    "    ∇Jfd[i][j]=(𝓁(neural_net(params.+ϵ,x)[1][N+1],y)-𝓁(neural_net(params.-ϵ,x)[1][N+1],y))/2𝜀\n",
    "    ϵ[i][j] = .0\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Matrix Neural Network\n",
    "- [] needed to create a box type\n",
    "- [] There are some issues with adjoint, did we assume transpose recursive in the article? If it is below code works accordingly.\n",
    "- [] However, adjoint definitions for ⊗, ⊗′ problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 411 methods)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: .+,.*,.-,+,-,*,zero,one,adjoint,inv,/,./,convert,size,isequal,iszero,getindex, setindex!\n",
    "\n",
    "abstract type Op; end\n",
    "struct (⊗) <: Op; A; B; end\n",
    "struct ⊗′ <: Op; A; B; end\n",
    "struct Δ  <: Op; A; end\n",
    "\n",
    "-(K::⊗′) = -K.A ⊗′ K.B \n",
    "*(K::⊗′,X::Union{AbstractArray,Number}) = K.B * (K.A * X) # changing paranthesis gives wrong result\n",
    "adjoint(K::⊗′) = K.B ⊗′ K.A' # same issue with kronocker adjoint\n",
    "\n",
    "-(K::⊗) = -K.A ⊗ K.B\n",
    "*(K::⊗,X::Union{AbstractArray,Number}) = (K.B * X) * K.A' # changing paranthesis gives dimension errors\n",
    "adjoint(K::⊗) = K.A' ⊗ K.B  # not consistent with adjoint of kroncker, if we keep consistent\n",
    "                            # then the elements of D becomes X[j]' ⊗ Δ(δ[i])', not consistent with article\n",
    "\n",
    "-(X::Δ) = Δ(-X.A)\n",
    "*(X::Δ,Y::Union{AbstractArray,Number}) = X.A .* Y\n",
    "*(Y::Union{AbstractArray,Number},X::Δ) = Y .* X.A\n",
    "adjoint(X::Δ) = Δ(X.A')\n",
    "\n",
    "# I can't think another way than boxing elements \n",
    "#to handle with zeros and ones requires by the backslash and triangular matrices\n",
    "struct Box; K; end\n",
    "# Unary Definitions\n",
    "zero(::Type{Box}) = Box(0)\n",
    "one(::Type{Box}) = Box(1)\n",
    "zero(::Box) = zero(Box)\n",
    "one(::Box) = one(Box)\n",
    "value(R::Box) = R.K\n",
    "iszero(R::Box) = R.K==0\n",
    "adjoint(R::Box) = Box(adjoint(R.K))\n",
    "inv(R::Box) = Box(inv(R.K))\n",
    "#Binary Definitions\n",
    "convert(::Type{Box},x::Union{Number,V,T}) where V <: Op where T <: AbstractArray = Box(x)\n",
    "/(X::Number,R::Box) = Box(X*inv(R))\n",
    "/(R1::Box,R2::Box) = Box(R1*inv(R2))\n",
    "-(R::Box) = Box(-R.K)\n",
    "-(R::Box, X::AbstractArray) = Box(R.K-X)\n",
    "-(X::AbstractArray,R::Box)  = Box(X-R.K)\n",
    "-(R1::Box,R2::Box) = Box(R1.K.-R2.K)\n",
    "+(R1::Box,R2::Box) = Box(R1.K.+R2.K)\n",
    "*(R1::Box,R2::Box) = Box(R1.K*R2.K)\n",
    "*(R::Box,X::Union{Number,V,T}) where V <: Op where T <: AbstractArray = Box(R.K * X)\n",
    "*(X::Union{Number,V,T},R::Box) where V <: Op where T <: AbstractArray = Box(X * R.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Needed to overwrite naivesub!, see comment in 12th line\n",
    "import LinearAlgebra: naivesub!, has_offset_axes\n",
    "function naivesub!(A::UnitUpperTriangular, b::AbstractVector, x::AbstractVector = b)\n",
    "    @assert !has_offset_axes(A, b, x)\n",
    "    n = size(A, 2)\n",
    "    if !(n == length(b) == length(x))\n",
    "        throw(DimensionMismatch(\"second dimension of left hand side A, $n, length of output x, $(length(x)), and length of right hand side b, $(length(b)), must be equal\"))\n",
    "    end\n",
    "    @inbounds for j in n:-1:1\n",
    "        xj = x[j] = b[j]\n",
    "        for i in j-1:-1:1\n",
    "            if !iszero(A.data[i,j]) # EKIN: added this line to solve zero shape related problem. \n",
    "                                    # Otherwise, in matrix neural network we get dimension mismastch\n",
    "                b[i] -= A.data[i,j] * xj\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    x\n",
    "end\n",
    "\n",
    "array(x) = fill(x,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    for i=1:length(params)\n",
    "        x = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(x))\n",
    "        push!(δ,h′.(x,X[i+1]))\n",
    "    end \n",
    "    X,δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Array{Float64,N} where N,1},1}:\n",
       " [[-0.364712 0.144268 1.23095; -0.89484 -0.399452 -0.991036; 0.573454 -0.491818 -0.732605], [-0.275151, 0.433567, -0.21384]]\n",
       " [[0.833144 -0.64884 -0.713167; 1.30563 -0.551628 1.20049; 0.78175 -0.393685 0.156015], [-1.20916, 0.699874, 1.36389]]      \n",
       " [[-0.348164 -0.393493 0.507356], [0.0681898]]                                                                              "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [3 3 3 1]\n",
    "N = length(n)-1\n",
    "B = 7\n",
    "W = [randn(n[i+1],n[i]) for i=1:N]\n",
    "b = [randn(n[i+1]) for i=1:N]\n",
    "params =[[W[i],b[i]] for i=1:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,2},1}:\n",
       " [8.36974 11.4023 … 12.966 90.7926; -2.86048 -4.14977 … -4.47754 -46.5517; -4.67462 -7.267 … -9.03337 -105.503]            \n",
       " [-6.4221 -9.27072 … -10.9274 -105.357; -0.0658502 -0.0854999 … -0.0927914 -0.675302; 0.265256 0.355902 … 0.403374 3.04383]\n",
       " [-6.37543 -8.05009 … -9.04041 -50.748]                                                                                    "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = randn(1,B)*0.1\n",
    "x = randn(n[1],B)*0.1\n",
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[X[i]' ⊗  Δ(δ[i]) Δ(δ[i]')] for i=1:N])\n",
    "L = Bidiagonal(fill(Box(0),N), [Box(params[i][1] ⊗′ Δ(δ[i])) for i=2:N] , :L)\n",
    "f = [Box(0) for i=1:N]\n",
    "f[N] = 𝓁′(X[N+1],y)\n",
    "∇J = D'*array.((UnitUpperTriangular(-L')\\f))\n",
    "∇Jw = value.(first.(∇J))\n",
    "∇Jb = value.(getindex.(∇J,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Array{Float64,N} where N,1},1}:\n",
       " [[-13.2795 -5.12737 9.84107; 5.61082 2.92235 -6.03449; 15.0273 6.62905 -13.764], [184.322, -77.7411, -180.31]]     \n",
       " [[-225.501 -121.406 -254.018; -1.58558 -0.838219 -1.73198; 7.19316 3.79558 7.89745], [-188.942, -1.30391, 5.92884]]\n",
       " [[-542.681 -3.31367 -11.6858], [-114.064]]                                                                         "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(params), wb=1:2\n",
    "    for j=1:length(ϵ[i][wb])\n",
    "            ϵ[i][wb][j] = 𝜀\n",
    "            ∇Jfd[i][wb][j] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "            ϵ[i][wb][j] = .0\n",
    "     end\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -13.2795   -5.12737    9.84107\n",
       "   5.61082   2.92235   -6.03449\n",
       "  15.0273    6.62905  -13.764  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -13.2795   -5.12737    9.84107\n",
       "   5.61082   2.92235   -6.03449\n",
       "  15.0273    6.62905  -13.764  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jw[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  184.32190001085758\n",
       "  -77.74109494530279\n",
       " -180.30987600941017"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1 Array{Float64,2}:\n",
       "  184.3218969749331 \n",
       "  -77.7410934801986 \n",
       " -180.30986442829192"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(∇Jb[1];dims=2) # biasses needs to be sum up in batch dimension, since they are broadcasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densely Connected Matrix Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] Defined step matrices to make D'* possible with generic zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 411 methods)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Horizontal Step Matrix\n",
    "    [---\n",
    "        ---\n",
    "           ---]\n",
    "\n",
    "Vertical Step Matrix\n",
    "    [|\n",
    "     |\n",
    "       |\n",
    "       |\n",
    "       |\n",
    "         |]\n",
    "\"\"\"\n",
    "abstract type StepMatrix{T} <: AbstractMatrix{T}; end;\n",
    "size(S::StepMatrix) = (S.m, S.n)\n",
    "\n",
    "struct VerticalStepMatrix{T} <: StepMatrix{T}\n",
    "    m::Int\n",
    "    n::Int\n",
    "    colptr::Vector{Int}\n",
    "    values::Vector{T}    \n",
    "    function VerticalStepMatrix{T}(m::Int, n::Int, colptr::Vector{Int},values::Vector{T}) where T\n",
    "        m < 0 && error(\"rows m $m\")\n",
    "        n < 0 && error(\"rows n $n\")\n",
    "        new(Int(m), Int(n), colptr, values)\n",
    "    end\n",
    "end\n",
    "\n",
    "getindex(S::VerticalStepMatrix{T},i::Integer, j::Integer) where T = (S.colptr[i] == j ? values[i] : zero(T))\n",
    "setindex!(S::VerticalStepMatrix{T},value::T,i::Integer,j::Integer) where T = (S.colptr[i] = j; values[i] = value)\n",
    "VerticalStepMatrix(t::Type{T},m::Int,n::Int) where T  = VerticalStepMatrix{T}(m, n, Vector{Int}(undef,m),Vector{T}(undef,m))\n",
    "\n",
    "struct HorizontalStepMatrix{T} <: StepMatrix{T}\n",
    "    m::Int\n",
    "    n::Int\n",
    "    rowptr::Vector{Int}\n",
    "    values::Vector{T}    \n",
    "    function HorizontalStepMatrix{T}(m::Int, n::Int, colptr::Vector{Int},values::Vector{T}) where T\n",
    "        m < 0 && error(\"rows m $m\")\n",
    "        n < 0 && error(\"rows n $n\")\n",
    "        new(Int(m), Int(n), colptr, values)\n",
    "    end\n",
    "end\n",
    "getindex(S::HorizontalStepMatrix{T},i::Integer, j::Integer) where T = (S.rowptr[j] == i ? S.values[j] : zero(T))\n",
    "setindex!(S::HorizontalStepMatrix{T},value::T, i::Integer, j::Integer) where T = (S.rowptr[j] = i; S.values[j] = value)\n",
    "HorizontalStepMatrix(t::Type{T},m::Integer, n::Integer) where T  = HorizontalStepMatrix{T}(m, n, Vector{Int}(undef,n),Vector{T}(undef,n))\n",
    "\n",
    "adjoint(S::VerticalStepMatrix{T}) where T = HorizontalStepMatrix{T}(S.n,S.m, S.colptr, adjoint.(S.values))\n",
    "adjoint(S::HorizontalStepMatrix{T}) where T = VerticalStepMatrix{T}(S.n,S.m, S.rowptr, adjoint.(S.values))\n",
    "\n",
    "function (*)(S::VerticalStepMatrix{T}, X::AbstractVector) where T\n",
    "    results = Vector{T}(undef,S.m)\n",
    "    for i=1:S.m\n",
    "        results[i] = S.values[i] * X[S.colptr[i]]\n",
    "    end\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    layeroffset = 0; i = 1\n",
    "    while layeroffset < length(params)\n",
    "       x = zeros(n[i+1],B)\n",
    "       for j=1:i\n",
    "           x += params[layeroffset+j]*X[j]  \n",
    "       end    \n",
    "       push!(X,h.(x .+ params[layeroffset+i+1]))\n",
    "       push!(δ,h′.(x,X[i+1]))\n",
    "       i+=1; layeroffset+=i\n",
    "    end \n",
    "    X,δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [2 3 2 1]\n",
    "N = length(n)-1\n",
    "B = 7\n",
    "params = []\n",
    "for i=1:N\n",
    "    wi = []\n",
    "    for j=1:i\n",
    "        push!(params,randn(n[i+1],n[j]))\n",
    "    end\n",
    "    push!(params,randn(n[i+1]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{Array{Float64,2},1}:\n",
       " [6.55357e-7 -5.60905e-7; 5.52284e-6 -3.8049e-6; -3.02292e-7 2.33001e-7]                                                                        \n",
       " [-1.4427e-8 2.67441e-6 … 5.84388e-9 1.22249e-6; -1.18827e-7 1.9039e-5 … 5.60568e-8 7.0659e-6; 5.96991e-9 -1.15829e-6 … -2.36938e-9 -4.57883e-7]\n",
       " [-1.4041e-7 1.05284e-7; 5.60857e-6 -4.30496e-6]                                                                                                \n",
       " [-1.58873e-6 -8.97747e-7 -4.38173e-7; 6.42688e-5 3.61923e-5 1.76933e-5]                                                                        \n",
       " [3.70509e-9 -5.04579e-7 … -1.92665e-9 -2.19364e-7; -1.28588e-7 2.09442e-5 … 5.89779e-8 8.79205e-6]                                             \n",
       " [-4.52938e-7 3.33163e-7]                                                                                                                       \n",
       " [-5.12828e-6 -2.91306e-6 -1.41792e-6]                                                                                                          \n",
       " [-1.05468e-6 -1.85894e-5]                                                                                                                      \n",
       " [9.30544e-9 -1.67356e-6 … -3.944e-9 -6.33433e-7]                                                                                               "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = randn(1,B)*0.1\n",
    "x = randn(n[1],B)*0.1\n",
    "X,δ = neural_net(params,x)\n",
    "D = HorizontalStepMatrix(Box,N,sum(2:N+1))\n",
    "L = LowerTriangular(zeros(Box,N,N))\n",
    "for i=1:N\n",
    "    layeroffset = sum(2:i)\n",
    "    for j=1:i\n",
    "        D[i,layeroffset+j] = Box(X[j]' ⊗ Δ(δ[i]))\n",
    "        if i>1 && j!=i\n",
    "            L[i,j] = Box(params[layeroffset+j+1] ⊗′ Δ(δ[i]))\n",
    "        end\n",
    "    end\n",
    "    D[i,layeroffset+i+1] = Box(Δ(δ[i]'))\n",
    "end\n",
    "\n",
    "f = [Box(0) for i=1:N] # [zeros(n[i+1],B) for i=1:N] may use this without modifying naivesub!. However,matrix neural network won't work \n",
    "f[N] = 𝓁′(X[N+1],y)\n",
    "\n",
    "∇J=D'*(UnitUpperTriangular(-L')\\f) # Trick: I-L' = UnitUpperTriangular(-L')\n",
    "∇J=value.(∇J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{Array{Float64,N} where N,1}:\n",
       " [6.55357e-7 -5.60905e-7; 5.52284e-6 -3.8049e-6; -3.02292e-7 2.33e-7]   \n",
       " [5.77296e-6, 4.60926e-5, -2.59625e-6]                                  \n",
       " [-1.4041e-7 1.05284e-7; 5.60857e-6 -4.30496e-6]                        \n",
       " [-1.58873e-6 -8.97747e-7 -4.38173e-7; 6.42688e-5 3.61923e-5 1.76933e-5]\n",
       " [-1.186e-6, 4.79291e-5]                                                \n",
       " [-4.52938e-7 3.33163e-7]                                               \n",
       " [-5.12828e-6 -2.91306e-6 -1.41792e-6]                                  \n",
       " [-1.05468e-6 -1.85894e-5]                                              \n",
       " [-3.84028e-6]                                                          "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(params)\n",
    "    for j=1:length(ϵ[i])\n",
    "            ϵ[i][j] = 𝜀\n",
    "            ∇Jfd[i][j] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "            ϵ[i][j] = .0\n",
    "     end\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Array{Float64,2}:\n",
       "  6.55357e-7  -5.60905e-7\n",
       "  5.52284e-6  -3.8049e-6 \n",
       " -3.02292e-7   2.33001e-7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Array{Float64,2}:\n",
       "  6.55357e-7  -5.60905e-7\n",
       "  5.52284e-6  -3.8049e-6 \n",
       " -3.02292e-7   2.33e-7   "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×7 Array{Float64,2}:\n",
       " -1.4427e-8    2.67441e-6  -4.91386e-8  …   5.84388e-9   1.22249e-6\n",
       " -1.18827e-7   1.9039e-5   -5.46281e-7      5.60568e-8   7.0659e-6 \n",
       "  5.96991e-9  -1.15829e-6   2.04782e-8     -2.36938e-9  -4.57883e-7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[2] # biasses needs to be sum up in batch dimension, since they are broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1 Array{Float64,2}:\n",
       "  5.772956965034854e-6\n",
       "  4.609262547142157e-5\n",
       " -2.59624744148595e-6 "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[2] = sum(∇J[2];dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  5.772956904182003e-6 \n",
       "  4.609263155180843e-5 \n",
       " -2.5962474531349145e-6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
