{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x) = exp(-x)\n",
    "h′(x,y) = -y\n",
    "𝓁(x,y) = sum(abs2,x-y)/2\n",
    "𝓁′(x,y) = x-y\n",
    "𝜀 = .0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [0.81055, -0.372367]\n",
       " [2.74526, 1.16666]  \n",
       " [-0.219741, 0.53361]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3 \n",
    "w = randn(N)\n",
    "b = randn(N)\n",
    "params =[[w[i],b[i]] for i=1:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params, input; h=h, h′=h′, N=length(params))\n",
    "    δ = [];\n",
    "    X = [input];\n",
    "    for i=1:N\n",
    "        x = params[i]⋅[X[i],1]\n",
    "        y = h.(x) \n",
    "        push!(δ, h′.(x,y))\n",
    "        push!(X,y)\n",
    "    end\n",
    "    return X,δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [0.000200208, 0.00054681]   \n",
       " [-0.000199184, -0.000184682]\n",
       " [-0.00084045, -0.0521265]   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand()\n",
    "y = 0.5\n",
    "X,δ   = neural_net(params,x)\n",
    "L     = Bidiagonal(zeros(N),δ[2:N].*w[2:N],:L)\n",
    "D     = Diagonal(δ.*[[X[i],1]' for i=1:N])\n",
    "f     = [zeros(N-1);𝓁′(X[N+1],y)]\n",
    "∇J    = D'*((I-L')\\f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [0.000200208, 0.00054681]   \n",
       " [-0.000199184, -0.000184682]\n",
       " [-0.00084045, -0.0521265]   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd = ∇J * 0\n",
    "ϵ    = ∇J * 0\n",
    "for i=1:N, j=1:2       \n",
    "    ϵ[i][j] = 𝜀\n",
    "    ∇Jfd[i][j]=(𝓁(neural_net(params.+ϵ,x)[1][N+1],y)-𝓁(neural_net(params.-ϵ,x)[1][N+1],y))/2𝜀\n",
    "    ϵ[i][j] = .0\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Matrix Neural Network\n",
    "- [] needed to create a box type\n",
    "- [] There are some issues with adjoint, did we assume transpose recursive in the article? If it is below code works accordingly.\n",
    "- [] However, adjoint definitions for ⊗, ⊗′ problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 350 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: +,-,*,/,zero,one,adjoint,convert,inv,size,iszero\n",
    "\n",
    "abstract type Op; end\n",
    "struct (⊗) <: Op; A; B; end\n",
    "struct ⊗′ <: Op; A; B; end\n",
    "struct Δ  <: Op; A; end\n",
    "\n",
    "-(K::⊗′) = -K.A ⊗′ K.B \n",
    "*(K::⊗′,X::Union{AbstractArray,Number}) = K.B * (K.A * X) # changing paranthesis gives wrong result\n",
    "adjoint(K::⊗′) = K.B ⊗′ K.A' # same issue with kronocker adjoint\n",
    "\n",
    "-(K::⊗) = -K.A ⊗ K.B\n",
    "*(K::⊗,X::Union{AbstractArray,Number}) = (K.B * X) * K.A' # changing paranthesis gives dimension errors\n",
    "adjoint(K::⊗) = K.A' ⊗ K.B  # not consistent with adjoint of kroncker, if we keep consistent\n",
    "                            # then the elements of D becomes X[j]' ⊗ Δ(δ[i])', not consistent with article\n",
    "\n",
    "-(X::Δ) = Δ(-X.A)\n",
    "*(X::Δ,Y::Union{AbstractArray,Number}) = X.A .* Y\n",
    "*(Y::Union{AbstractArray,Number},X::Δ) = Y .* X.A\n",
    "adjoint(X::Δ) = Δ(X.A')\n",
    "\n",
    "# I can't think another way than boxing elements \n",
    "#to handle with zeros and ones requires by the backslash and triangular matrices\n",
    "struct Box; K; end\n",
    "# Unary Definitions\n",
    "zero(::Type{Box}) = Box(0)\n",
    "one(::Type{Box}) = Box(1)\n",
    "zero(::Box) = zero(Box)\n",
    "one(::Box) = one(Box)\n",
    "value(R::Box) = R.K\n",
    "iszero(R::Box) = R.K==0\n",
    "adjoint(R::Box) = Box(adjoint(R.K))\n",
    "inv(R::Box) = Box(inv(R.K))\n",
    "#Binary Definitions\n",
    "convert(::Type{Box},x::Union{Number,V,T}) where V <: Op where T <: AbstractArray = Box(x)\n",
    "/(X::Number,R::Box) = Box(X*inv(R))\n",
    "/(R1::Box,R2::Box) = Box(R1*inv(R2))\n",
    "-(R::Box) = Box(-R.K)\n",
    "-(R::Box, X::AbstractArray) = Box(R.K-X)\n",
    "-(X::AbstractArray,R::Box)  = Box(X-R.K)\n",
    "-(R1::Box,R2::Box) = Box(R1.K.-R2.K)\n",
    "+(R1::Box,R2::Box) = Box(R1.K.+R2.K)\n",
    "*(R1::Box,R2::Box) = Box(R1.K*R2.K)\n",
    "*(R::Box,X::Union{Number,V,T}) where V <: Op where T <: AbstractArray = Box(R.K * X)\n",
    "*(X::Union{Number,V,T},R::Box) where V <: Op where T <: AbstractArray = Box(X * R.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Needed to overwrite naivesub!, see comment in 12th line\n",
    "import LinearAlgebra: naivesub!, has_offset_axes\n",
    "function naivesub!(A::UnitUpperTriangular, b::AbstractVector, x::AbstractVector = b)\n",
    "    @assert !has_offset_axes(A, b, x)\n",
    "    n = size(A, 2)\n",
    "    if !(n == length(b) == length(x))\n",
    "        throw(DimensionMismatch(\"second dimension of left hand side A, $n, length of output x, $(length(x)), and length of right hand side b, $(length(b)), must be equal\"))\n",
    "    end\n",
    "    @inbounds for j in n:-1:1\n",
    "        xj = x[j] = b[j]\n",
    "        for i in j-1:-1:1\n",
    "            if !iszero(A.data[i,j]) # EKIN: added this line to solve zero shape related problem. \n",
    "                                    # Otherwise, in matrix neural network we get dimension mismastch\n",
    "                b[i] -= A.data[i,j] * xj\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    x\n",
    "end\n",
    "\n",
    "array(x) = fill(x,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    for i=1:length(params)\n",
    "        x = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(x))\n",
    "        push!(δ,h′.(x,X[i+1]))\n",
    "    end \n",
    "    X,δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Array{Float64,N} where N,1},1}:\n",
       " [[-0.049471 0.396971 0.706293; 0.298809 0.394277 -0.539425; -0.319241 0.927687 -0.20654], [-0.842948, 0.030618, 0.674276]]\n",
       " [[-0.129688 0.472665 0.465445; -0.395151 1.22697 -1.40906; 0.481917 0.778302 0.200718], [0.708873, -1.27867, -0.579021]]  \n",
       " [[-2.06629 0.817443 0.960496], [-1.60267]]                                                                                "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [3 3 3 1]\n",
    "N = length(n)-1\n",
    "B = 7\n",
    "W = [randn(n[i+1],n[i]) for i=1:N]\n",
    "b = [randn(n[i+1]) for i=1:N]\n",
    "params =[[W[i],b[i]] for i=1:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Any,2},1}:\n",
       " [Box([-0.00928111 -0.0082192 0.0257615; 0.0166787 0.0150493 -0.0442492; -0.00925947 -0.00969559 0.0275945]); Box([0.00784546 0.0479041 … 0.101229 0.0590256; -0.0119298 -0.072742 … -0.180598 -0.0828348; 0.00852024 0.0476893 … 0.108329 0.0513433])]\n",
       " [Box([-0.137948 -0.0650087 -0.0329402; 0.878694 0.413408 0.210159; 0.0505024 0.0238361 0.0120744]); Box([-0.00143202 -0.00807506 … -0.0224207 -0.0120017; 0.0102811 0.057048 … 0.136611 0.0752457; 0.000552706 0.00267994 … 0.0083395 0.0043266])]    \n",
       " [Box([-0.0302885 -0.487081 -0.0238861]); Box([-0.00218138 -0.0125983 … -0.0361146 -0.0168697])]                                                                                                                                                       "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = randn(1,B)*0.1\n",
    "x = randn(n[1],B)*0.1\n",
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[X[i]' ⊗  Δ(δ[i]) Δ(δ[i]')] for i=1:N])\n",
    "L = Bidiagonal(fill(Box(0),N), [Box(params[i][1] ⊗′ Δ(δ[i])) for i=2:N] , :L)\n",
    "f = [Box(0) for i=1:N]\n",
    "f[N] = 𝓁′(X[N+1],y)\n",
    "∇J = D'*array.((UnitUpperTriangular(-L')\\f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Array{Float64,N} where N,1},1}:\n",
       " [[-0.00928111 -0.0082192 0.0257615; 0.0166787 0.0150493 -0.0442492; -0.00925947 -0.00969559 0.0275945], [0.304989, -0.495064, 0.309034]]\n",
       " [[-0.137948 -0.0650087 -0.0329402; 0.878695 0.413408 0.210159; 0.0505024 0.0238361 0.0120744], [-0.0625849, 0.398161, 0.0229425]]       \n",
       " [[-0.0302885 -0.487082 -0.0238861], [-0.0966351]]                                                                                       "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(params), wb=1:2\n",
    "    for j=1:length(ϵ[i][wb])\n",
    "            ϵ[i][wb][j] = 𝜀\n",
    "            ∇Jfd[i][wb][j] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "            ϵ[i][wb][j] = .0\n",
    "     end\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.00928111  -0.0082192    0.0257615\n",
       "  0.0166787    0.0150493   -0.0442492\n",
       " -0.00925947  -0.00969559   0.0275945"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.00928111  -0.0082192    0.0257615\n",
       "  0.0166787    0.0150493   -0.0442492\n",
       " -0.00925947  -0.00969559   0.0275945"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value(∇J[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  0.30498881260977717\n",
       " -0.49506397154910897\n",
       "  0.30903439150652134"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1 Array{Float64,2}:\n",
       "  0.3049888100342567 \n",
       " -0.4950639037319157 \n",
       "  0.30903438608774825"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(value(∇J[1][2]);dims=2) # biasses needs to be sum up in batch dimension, since they are broadcasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densely Connected Matrix Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] Defined step matrices to make D'* possible with generic zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 351 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: getindex, setindex!\n",
    "\"\"\"\n",
    "Horizontal Step Matrix\n",
    "    [---\n",
    "        ---\n",
    "           ---]\n",
    "\n",
    "Vertical Step Matrix\n",
    "    [|\n",
    "     |\n",
    "       |\n",
    "       |\n",
    "       |\n",
    "         |]\n",
    "\"\"\"\n",
    "abstract type StepMatrix{T} <: AbstractMatrix{T}; end;\n",
    "size(S::StepMatrix) = (S.m, S.n)\n",
    "\n",
    "struct VerticalStepMatrix{T} <: StepMatrix{T}\n",
    "    m::Int\n",
    "    n::Int\n",
    "    colptr::Vector{Int}\n",
    "    values::Vector{T}    \n",
    "    function VerticalStepMatrix{T}(m::Int, n::Int, colptr::Vector{Int},values::Vector{T}) where T\n",
    "        m < 0 && error(\"rows m $m\")\n",
    "        n < 0 && error(\"rows n $n\")\n",
    "        new(Int(m), Int(n), colptr, values)\n",
    "    end\n",
    "end\n",
    "\n",
    "getindex(S::VerticalStepMatrix{T},i::Integer, j::Integer) where T = (S.colptr[i] == j ? values[i] : zero(T))\n",
    "setindex!(S::VerticalStepMatrix{T},value::T,i::Integer,j::Integer) where T = (S.colptr[i] = j; values[i] = value)\n",
    "VerticalStepMatrix(t::Type{T},m::Int,n::Int) where T  = VerticalStepMatrix{T}(m, n, Vector{Int}(undef,m),Vector{T}(undef,m))\n",
    "\n",
    "struct HorizontalStepMatrix{T} <: StepMatrix{T}\n",
    "    m::Int\n",
    "    n::Int\n",
    "    rowptr::Vector{Int}\n",
    "    values::Vector{T}    \n",
    "    function HorizontalStepMatrix{T}(m::Int, n::Int, colptr::Vector{Int},values::Vector{T}) where T\n",
    "        m < 0 && error(\"rows m $m\")\n",
    "        n < 0 && error(\"rows n $n\")\n",
    "        new(Int(m), Int(n), colptr, values)\n",
    "    end\n",
    "end\n",
    "getindex(S::HorizontalStepMatrix{T},i::Integer, j::Integer) where T = (S.rowptr[j] == i ? S.values[j] : zero(T))\n",
    "setindex!(S::HorizontalStepMatrix{T},value::T, i::Integer, j::Integer) where T = (S.rowptr[j] = i; S.values[j] = value)\n",
    "HorizontalStepMatrix(t::Type{T},m::Integer, n::Integer) where T  = HorizontalStepMatrix{T}(m, n, Vector{Int}(undef,n),Vector{T}(undef,n))\n",
    "\n",
    "adjoint(S::VerticalStepMatrix{T}) where T = HorizontalStepMatrix{T}(S.n,S.m, S.colptr, adjoint.(S.values))\n",
    "adjoint(S::HorizontalStepMatrix{T}) where T = VerticalStepMatrix{T}(S.n,S.m, S.rowptr, adjoint.(S.values))\n",
    "\n",
    "function (*)(S::VerticalStepMatrix{T}, X::AbstractVector) where T\n",
    "    results = Vector{T}(undef,S.m)\n",
    "    for i=1:S.m\n",
    "        results[i] = S.values[i] * X[S.colptr[i]]\n",
    "    end\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    layeroffset = 0; i = 1\n",
    "    while layeroffset < length(params)\n",
    "       x = zeros(n[i+1],B)\n",
    "       for j=1:i\n",
    "           x += params[layeroffset+j]*X[j]  \n",
    "       end    \n",
    "       push!(X,h.(x .+ params[layeroffset+i+1]))\n",
    "       push!(δ,h′.(x,X[i+1]))\n",
    "       i+=1; layeroffset+=i\n",
    "    end \n",
    "    X,δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [2 3 2 1]\n",
    "N = length(n)-1\n",
    "B = 7\n",
    "params = []\n",
    "for i=1:N\n",
    "    wi = []\n",
    "    for j=1:i\n",
    "        push!(params,randn(n[i+1],n[j]))\n",
    "    end\n",
    "    push!(params,randn(n[i+1]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{Array{Float64,2},1}:\n",
       " [-1.36359e-5 9.07862e-5; 4.37527e-6 1.543e-5; -7.8821e-6 4.56613e-5]                                                                                       \n",
       " [0.000594278 -5.12599e-5 … -0.000350615 0.00174952; 0.000141013 -9.53719e-6 … -0.000137171 0.000485491; 0.000280163 -2.47653e-5 … -0.000144873 0.000786784]\n",
       " [-3.20617e-7 4.22191e-6; -1.35161e-6 6.97848e-5]                                                                                                           \n",
       " [-2.35714e-5 -1.62807e-5 -1.46287e-5; -0.000295201 -0.000201111 -0.000187431]                                                                              \n",
       " [2.07296e-5 -1.12619e-6 … -9.49229e-6 5.54215e-5; 0.000526085 -4.14134e-5 … -0.000395982 0.0016692]                                                        \n",
       " [-1.68009e-6 -2.14735e-5]                                                                                                                                  \n",
       " [0.000104647 7.61552e-5 6.55572e-5]                                                                                                                        \n",
       " [0.000104149 0.000469868]                                                                                                                                  \n",
       " [-0.000137767 6.90225e-6 … 0.000107981 -0.000444295]                                                                                                       "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = randn(1,B)*0.1\n",
    "x = randn(n[1],B)*0.1\n",
    "X,δ = neural_net(params,x)\n",
    "D = HorizontalStepMatrix(Box,N,sum(2:N+1))\n",
    "L = LowerTriangular(zeros(Box,N,N))\n",
    "for i=1:N\n",
    "    layeroffset = sum(2:i)\n",
    "    for j=1:i\n",
    "        D[i,layeroffset+j] = Box(X[j]' ⊗ Δ(δ[i]))\n",
    "        if i>1 && j!=i\n",
    "            L[i,j] = Box(params[layeroffset+j+1] ⊗′ Δ(δ[i]))\n",
    "        end\n",
    "    end\n",
    "    D[i,layeroffset+i+1] = Box(Δ(δ[i]'))\n",
    "end\n",
    "\n",
    "f = [Box(0) for i=1:N] # [zeros(n[i+1],B) for i=1:N] may use this without modifying naivesub!. However,matrix neural network won't work \n",
    "f[N] = 𝓁′(X[N+1],y)\n",
    "\n",
    "∇J=D'*(UnitUpperTriangular(-L')\\f) # Trick: I-L' = UnitUpperTriangular(-L')\n",
    "∇J=value.(∇J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{Array{Float64,N} where N,1}:\n",
       " [-1.36359e-5 9.07862e-5; 4.37527e-6 1.543e-5; -7.8821e-6 4.56613e-5]         \n",
       " [-0.000335133, -6.85026e-5, -0.000180574]                                    \n",
       " [-3.20617e-7 4.22191e-6; -1.35161e-6 6.97848e-5]                             \n",
       " [-2.35714e-5 -1.62807e-5 -1.46287e-5; -0.000295201 -0.000201111 -0.000187431]\n",
       " [-2.11552e-5, -0.000260842]                                                  \n",
       " [-1.68009e-6 -2.14735e-5]                                                    \n",
       " [0.000104647 7.61552e-5 6.55572e-5]                                          \n",
       " [0.000104149 0.000469868]                                                    \n",
       " [9.5503e-5]                                                                  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(params)\n",
    "    for j=1:length(ϵ[i])\n",
    "            ϵ[i][j] = 𝜀\n",
    "            ∇Jfd[i][j] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "            ϵ[i][j] = .0\n",
    "     end\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Array{Float64,2}:\n",
       " -1.36359e-5  9.07862e-5\n",
       "  4.37527e-6  1.543e-5  \n",
       " -7.8821e-6   4.56613e-5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Array{Float64,2}:\n",
       " -1.36359e-5  9.07862e-5\n",
       "  4.37527e-6  1.543e-5  \n",
       " -7.8821e-6   4.56613e-5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×7 Array{Float64,2}:\n",
       " 0.000594278  -5.12599e-5  -0.000559212  …  -0.000350615  0.00174952 \n",
       " 0.000141013  -9.53719e-6  -0.000137091     -0.000137171  0.000485491\n",
       " 0.000280163  -2.47653e-5  -0.000257162     -0.000144873  0.000786784"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[2] # biasses needs to be sum up in batch dimension, since they are broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×1 Array{Float64,2}:\n",
       " -0.00033513258877194453\n",
       " -6.850257717373547e-5  \n",
       " -0.00018057410778917003"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(∇J[2];dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.00033513258237971577\n",
       " -6.850257718710173e-5  \n",
       " -0.00018057410691718623"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
